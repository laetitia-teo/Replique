"""
Gan for 128*128 RGB images, distributed version.
Should be encapsulated inside the strategy context manager.
"""

import os.path as op

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from models128 import deep_gen, deep_discr

class GAN():
    """
    Wrapper for the GAN_core class.
    """
    def __init__(self,
                 data_path,
                 load_model=False,
                 batch_size=64):
        
        self.strategy = tf.distribute.MirroredStrategy()
        with self.strategy.scope:
            self.gan = GAN_core(data_path,
                                strategy,
                                load_model,
                                batch_size)
    
    def run(self, n_epochs):
        # no strategy scope here ?
        self.gan.run(n_epochs)
    
    def load(self):
        self.gan.load_from_ckpt()
    
    def plot(self):
        self.gan.plot_gen()


class GAN_core():
    """
    GAN core class, contains G (generative) and D (discriminative) networks.
    Wrapped in a higher-level class, for the use of distributed computation.
    """    
    def __init__(self, 
                 data_path,
                 strategy,
                 load_model=False,
                 batch_size=64):
        
        assert(tf.__version__ != '2.0.0-alpha0')
        
        self.strategy = strategy
        
        self.dataset = tf.data.TFRecordDataset(data_path)
        self.buffer_size = 0
        # need to get the dataset size manually
        print('fetching buffer size...')
        for _ in self.dataset:
            self.buffer_size += 1
        print('done')
        
        self.batch_size_per_replica = batch_size
        self.gobal_batch_size = self.batch_size_per_replica \
            * strategy.num_replicas_in_sync
        
        self.dataset = self.dataset.map(self._tf_parse)
        self.dataset = self.dataset.batch(self.global_batch_size)
        self.iterator = self.strategy.make_dataset_iterator(self.dataset)
        
        self.cross_entropy = tf.keras.losses.BinaryCrossEntropy(
            from_logits=True,
            reduction=tf.keras.losses.Reduction.NONE)
    
        # hyperparams
        self.z_dim = 500
        #self.k = k # number of discriminative optimization steps
        #self.m = m # number of generative optimization steps
        
        # defining the models
        self.gen = self.make_gen()
        self.discr = self.make_discr()
        
        # defining the optimizers
        # TODO : tune the learning rates : we may want them smaller ?
        self.gen_opt = tf.keras.optimizers.Adam(1e-4)
        self.discr_opt = tf.keras.optimizers.Adam(1e-4)
        
        # checkpoints for saving
        self.save_path = op.join('saves')
        self.gen_ckpt_prefix = op.join(self.save_path, "gen", "ckpt")
        self.gen_ckpt = tf.train.Checkpoint(optimizer=self.gen_opt,
                                            model=self.gen)
        self.discr_ckpt_prefix = op.join(self.save_path, "discr", "ckpt")
        self.discr_ckpt = tf.train.Checkpoint(optimizer=self.discr_opt,
                                              model=self.discr)
        self.init_checkpoint_paths()

    def _parse(data):
        """
        Parses the data contained in the tfrecords. Decodes the images and
        sends them to the [-1, 1] range.
        """
        imgs = tf.image.decode_image(data)
        imgs = tf.dtypes.cast(imgs, 'float32')
        imgs = (imgs - 127.5) / 127.5
        return imgs
    
    def _tf_parse(data):
        """
        Wrapping of the parsing function for mapping on the dataset (provides
        type and shape data).
        """
        imgs = tf.py_function(
            parse_image,
            (data,),
            tf.float32)
        return tf.reshape(imgs, (128, 128, 3))
    
    def _compute_loss(true, pred):
        """
        The reduction of the loss has to be computed explicitly in a distributed
        setting.
        """
        per_example_loss = self.loss_object(true, pred)
        return tf.reduce_sum(per_example_loss) * (1. / self.global_batch_size)
    
    def plot_gen(self):
        """
        Plots a grid of 8x8 images generated by the generator.
        """
        #self.training = False
        #saver = tf.train.Saver()
        gen_images = self.gen(self.sample_z(1), training=False)
        #print(gen_images)
        self.plot_images(gen_images[..., 0])
        #self.training = True
    
    def sample_z(self, num):
        """
        Function for generation of a random vector of noise in latent space, 
        with a gaussian prior.
        """
        return tf.random.normal([num, self.z_dim])
    
    def make_gen(self):
        """
        Returns the generator model.
        """
        return deep_gen128(self.z_dim)
    
    def make_discr(self):
        """
        Returns the discriminator model.
        """
        return deep_discr128()
    
    def gen_loss(self, gen_discr):
        """
        Returns generator loss.
        """
        total_loss = self.cross_entropy(tf.ones_like(gen_discr), gen_discr)
        loss = tf.reduce_sum(total_loss) / self.global_batch_size
        return loss
    
    def discr_loss(self, true_discr, gen_discr):
        """
        Returns discriminator loss.
        """
        true_loss = self.cross_entropy(tf.ones_like(true_discr), true_discr)
        gen_loss = self.cross_entropy(tf.zeros_like(gen_discr), gen_discr)
        loss = tf.reduce_sum(true_loss + gen_loss) / self.global_batch_size
        return loss
    
    def load_from_ckpt(self):
        """
        Loads the models saved in the last checkpoint.
        """
        if self.gen_path and self.discr_path:
            self.gen_ckpt.restore(self.gen_path)
            self.discr_ckpt.restore(self.discr_path)
        else:
            raise Warning('No model to load')
    
    def init_checkpoint_paths(self):
        try:
            pattern = r'"([A-Za-z0-9\-]*)"'
            with open(op.join('saves', 'gen', 'checkpoint')) as f:
                line = f.readlines()[0]
                ckpt = re.search(pattern, line)
                self.gen_path = op.join('saves', 'gen', ckpt[0][1:-1])
            with open(op.join('saves', 'discr', 'checkpoint')) as f:
                line = f.readlines()[0]
                ckpt = re.search(pattern, line)
                self.discr_path = op.join('saves', 'discr', ckpt[0][1:-1])
        except FileNotFoundError:
            self.gen_path = None
            self.discr_path = None
    
    def train_step(self, images):
        """
        One step of training.
        """
        z = self.sample_z(self.batch_size_per_replica)
        with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:
            
            # generated images
            gen_ims = self.gen(z, training=True)
            
            # result of the discriminator on the true images
            true_discr = self.discr(images, training=True)
            # and on the generated images
            gen_discr = self.discr(gen_ims, training=True)
            
            # losses of the two models
            gen_loss = self.gen_loss(gen_discr)
            discr_loss = self.discr_loss(true_discr, gen_discr)
        
        # variables of our models
        gen_vars = self.gen.trainable_variables
        discr_vars = self.discr.trainable_variables
        
        # gradients of our models
        gen_grads = gen_tape.gradient(gen_loss, gen_vars)
        discr_grads = discr_tape.gradient(discr_loss, discr_vars)
        
        print('gen_loss, discr_loss %s, %s' % (gen_loss, discr_loss))
        
        # optimization step
        self.gen_opt.apply_gradients(zip(gen_grads, gen_vars))
        self.discr_opt.apply_gradients(zip(discr_grads, discr_vars))
        return gen_loss, discr_loss
    
    @tf.function
    def distributed_train(self):
        return self.strategy.experimental_run(self.train_step,
                                              self.iterator)
    
    def run(self, n_epochs):
        """
        Performs training on the GAN for n_epochs.
        """
        for epoch in range(n_epochs):
            for _ in range(int(self.buffer_size / self.global_batch_size))
            
        # perform saving at the end of the training :
        self.gen_path = self.gen_ckpt.save(file_prefix=self.gen_ckpt_prefix)
        self.discr_path = self.discr_ckpt.save(file_prefix=self.discr_ckpt_prefix)
                
            







































