import os.path as op
import re
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from models import deep_gen, deep_discr

class GAN():
    """
    GAN class, contains G (generative) and D (discriminative) networks.
    """    
    def __init__(self, dataset, load_model=False, k=1, m=1):
        
        if (tf.__version__ != '2.0.0-alpha0'):
            tf.enable_eager_execution()
        
        self.batch_size = 64
        self.dataset = dataset # must support batch iteration
        self.dataset.batch_size = self.batch_size
        # hyperparams
        self.z_dim = 500
        #self.k = k # number of discriminative optimization steps
        #self.m = m # number of generative optimization steps
        
        # defining the models
        self.gen = self.make_gen(self.z_dim)
        self.discr = self.make_discr()
        
        # defining the cross-entropy (will be used for the loss)
        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(
            from_logits=True)
        
        # defining the optimizers
        self.gen_opt = tf.keras.optimizers.Adam(1e-4)
        self.discr_opt = tf.keras.optimizers.Adam(1e-4)
        
        # checkpoints for saving
        self.save_path = op.join('saves')
        self.gen_ckpt_prefix = op.join(self.save_path, "gen", "ckpt")
        self.gen_ckpt = tf.train.Checkpoint(optimizer=self.gen_opt,
                                            model=self.gen)
        self.discr_ckpt_prefix = op.join(self.save_path, "discr", "ckpt")
        self.discr_ckpt = tf.train.Checkpoint(optimizer=self.discr_opt,
                                              model=self.discr)
        self.init_checkpoint_paths()



    def plot_images(self, images):
        """
        Utility function for plotting 8x8 grids of mnist images.
        
        Args : 
            - images (numpy ndarray) : array of 64 mnist images for plotting. 
        """
        for i in range(8):
            for j in range(8):
                if j == 0:
                    row = images[8*i+j]
                else:
                    row = np.concatenate((row, images[8*i+j]), axis=1)
            if i == 0:
                stack = row
            else:
                stack = np.concatenate((stack, row), axis=0)
        plt.imshow(stack, cmap='gray')
        plt.show()
    
    def plot_gen(self):
        """
        Plots a grid of 8x8 images generated by the generator.
        """
        #self.training = False
        #saver = tf.train.Saver()
        gen_images = self.gen(self.sample_z(), training=False)
        #print(gen_images)
        self.plot_images(gen_images[:, :, :, 0])
        self.training = True
    
    def sample_z(self):
        """
        Function for generation of a random vector of noise in latent space, 
        with a gaussian prior.
        
        Args : 
            - n_samples (int) : number of samples to draw.
        """
        return tf.random.normal([self.batch_size, self.z_dim])
    
    def make_gen(self, z_dim):
        """
        Returns the generator model.
        """
        return deep_gen(z_dim)
    
    def make_discr(self):
        """
        Returns the discriminator model.
        """
        return deep_discr()
    
    def gen_loss(self, gen_discr):
        """
        Returns generator loss.
        """
        return self.cross_entropy(tf.ones_like(gen_discr), gen_discr)
    
    def discr_loss(self, true_discr, gen_discr):
        """
        Returns discriminator loss.
        """
        true_loss = self.cross_entropy(tf.ones_like(true_discr), true_discr)
        gen_loss = self.cross_entropy(tf.zeros_like(gen_discr), gen_discr)
        return true_loss + gen_loss
    
    def load_from_ckpt(self):
        """
        Loads the models saved in the last checkpoint.
        """
        if self.gen_path and self.discr_path:
            self.gen_ckpt.restore(self.gen_path)
            self.discr_ckpt.restore(self.discr_path)
        else:
            raise Warning('No model to load')
    
    def init_checkpoint_paths(self):
        try:
            pattern = r'"([A-Za-z0-9\-]*)"'
            with open(op.join('saves', 'gen', 'checkpoint')) as f:
                line = f.readlines()[0]
                ckpt = re.search(pattern, line)
                self.gen_path = op.join('saves', 'gen', ckpt[0][1:-1])
            with open(op.join('saves', 'discr', 'checkpoint')) as f:
                line = f.readlines()[0]
                ckpt = re.search(pattern, line)
                self.discr_path = op.join('saves', 'discr', ckpt[0][1:-1])
        except FileNotFoundError:
            self.gen_path = None
            self.discr_path = None
    
    def train(self, n_epochs):
        """
        Performs training on the GAN for n_epochs iterations on the dataset.
        """
        for i in range(n_epochs):
            for im_batch in self.dataset:
                print(im_batch.shape)
                z_batch = self.sample_z()
                with tf.GradientTape() as gen_tape, tf.GradientTape() as discr_tape:
                    
                    # generated images
                    gen_ims = self.gen(z_batch, training=True)
                    
                    # result of the discriminator on the true images
                    true_discr = self.discr(im_batch, training=True)
                    # and on the generated images
                    gen_discr = self.discr(gen_ims, training=True)
                    
                    # losses of the two models
                    gen_loss = self.gen_loss(gen_discr)
                    discr_loss = self.discr_loss(true_discr, gen_discr)
                
                # variables of our models
                gen_vars = self.gen.trainable_variables
                discr_vars = self.discr.trainable_variables
                
                # gradients of our models
                gen_grads = gen_tape.gradient(gen_loss, gen_vars)
                discr_grads = discr_tape.gradient(discr_loss, discr_vars)
                
                print('gen_loss, discr_loss %s, %s' % (gen_loss, discr_loss))
                
                # applying gradients according to the optimizers
                self.gen_opt.apply_gradients(zip(gen_grads, gen_vars))
                self.discr_opt.apply_gradients(zip(discr_grads, discr_vars))
            
            # perform saving at the end of the epoch :
        self.gen_path = self.gen_ckpt.save(file_prefix=self.gen_ckpt_prefix)
        self.discr_path = self.discr_ckpt.save(file_prefix=self.discr_ckpt_prefix)
                
            







































